{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering and displaying drawing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandapaco\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "This app collects data from all 1,900+ (and counting) drawings from an experienced furry artist and illustrator, Paco (aka pandapaco, or Paco Panda). The data will collect things such as:\n",
    "\n",
    "- Name and date of the artwork\n",
    "- Species and character names\n",
    "- Number of character in each artwork\n",
    "- Type (previously Medium) (either drawn digitally or traditional with exceptions of programs and tools used)\n",
    "- Medium (for tools/programs used in an artwork)\n",
    "- Source (either from FurAffinity or DeviantArt)\n",
    "\n",
    "I was also planning to get the most colors used, as in only in each characters, excluding backgrounds, items, etc. However, because I have deal with shading and color correction, it will be a tedious and cumbersome dataset to obtain; yes we can refer it to their fursona's ref sheet and get the colors that way but there are some cases that it won't be available, so for now - I won't add this dataset.\n",
    "\n",
    "The \"expressions\" dataset was removed on March 13, 2022 because it was too ambigious and difficult to determine to pinpoint an expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `species` and `characters` datasets\n",
    "\n",
    "Since there are 2 or more characters, and some duplicates - it'll be returned as an array for each `species` and `characters`. I assume that there are by average 3 to 6 characters he draws on each artwork.\n",
    "\n",
    "For generalizing the `species` data to the website, it's going to be explicitly categorized into, well... foxes, canines, cats, yeens, etc. Hybrids are categorized in their own category, while species like protogens, and other exotic and/or fictional species will be categorized as \"Others\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How this process works\n",
    "\n",
    "### Gathering the data\n",
    "Previously, I manually copy-pasted data from the sheets and would turn them into a JSON from the web app to be parsed. It took me a while to use a scraping method with BeautifulSoup library.\n",
    "\n",
    "So, I made `bs4` target Paco's gallery page on FurAffinity and get the title, description, date, and tags, then save them in a JSON file like so -- for demonstration purposes, we only get the title and date of each artwork, each gallery page has 48 items.\n",
    "\n",
    "The full code is available on `/server/fa-scraper.py`. DeviantArt support and other platforms coming soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_art = requests.get(f\"https://furaffinity.net/gallery/pacopanda/1/?\")\n",
    "parse_art = BeautifulSoup(find_art.text, 'html.parser')\n",
    "parse_art = parse_art.find_all('figure', {'id': re.compile(\"sid-*\")})\n",
    "\n",
    "print(f\"Title | Date | Link to the image\")\n",
    "\n",
    "for sid in parse_art:\n",
    "  if 'id' in sid.attrs:\n",
    "    sid_concat = re.sub('sid-', '', sid['id'])\n",
    "    find_art_id = requests.get(f\"https://furaffinity.net/view/{sid_concat}/\")\n",
    "    parse_art_id = BeautifulSoup(find_art_id.text, 'html.parser')\n",
    "\n",
    "    # Get title\n",
    "    find_title = parse_art_id.find('div', {'class': 'submission-title'})\n",
    "    art_title = find_title.find('p').get_text()\n",
    "\n",
    "    # Get image\n",
    "    detect_img = parse_art_id.find('div', {'class': 'aligncenter submission-area'})\n",
    "\n",
    "    if detect_img.find('img'):\n",
    "      art_image = parse_art_id.find('img', {'id': 'submissionImg'})['src']\n",
    "      art_image = f'https:{art_image}'\n",
    "\n",
    "    # If no image is detected (i.e. video or flash content); then return null\n",
    "    else:\n",
    "      art_image = 'null, item requested is anything other than an image.'\n",
    "\n",
    "    # Get date\n",
    "    art_date = parse_art_id.find('span', {'class': 'popup_date'})['title']\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{art_title} | {art_date} | {art_image}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "[This Google Sheet](https://docs.google.com/spreadsheets/d/1fpNL-qbfZ53H-6WdqEB2X9rwn9QmM1porJqKgBC7rPk/edit?usp=sharing) contains all raw data and get a slice of data as an example to truncate, summarize, visualize some data through the web browser.\n",
    "\n",
    "As an example, we'll take one of his artworks [*\"First Meet\"*](https://www.deviantart.com/pandapaco/art/First-Meet-901151258) and analyze it, the image is cropped for clarity.\n",
    "<p>\n",
    "  <a href=\"https://www.deviantart.com/pandapaco/art/First-Meet-901151258\">\n",
    "    <img src=\"img/first_meet_by_pandapaco.jpg\" width=\"600\">\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "Two characters are visible: which are Kazan and Steffen respectively, their species are wolf and an otter; the artwork is traditionally drawn taken from a camera. So overall, the result should be something like this in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shy_boi = ['12/19/21', 'First Meet', 'Kazan, Steffen', 'Wolf, Otter', 'Traditional'],\n",
    "\n",
    "pandapaco.DataFrame(shy_boi, columns = [\"Date\", \"Title\", \"Character(s)\", \"Species\", \"Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! And in other example, we'll use a huge dataset and will get data from his artwork from January 2021 alone. The column `source` is included in the sheets and shown the first 5 omitted for brevity; it should be something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paco_jan_dataset = pandapaco.read_csv('./csv/paco-jan2021.csv')\n",
    "paco_jan_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initally, I wrote a Python script below to convert an exported CSV files off of Google Sheets into JSON files... The only time I realized that this was the most dumbest thing I've made since D3 and Chart.js can read off of CSV files... lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting data\n",
    "Basing all the data from 2021 alone, first, we plot a pie chart for sums of artworks drawn in both digital and traditional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i paco-ds-types.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll get a number of species drawn from the dataset: from a horrible Python script I wrote, it decouples the `Species` column and merge into one big CSV file -- making a CSV file with a single column. Then, it'll read the decoupled CSV file to get a total sum for each species drawn, and finally filter the values in ascending order.\n",
    "\n",
    "The data below shows the first 10 of the species for simplicity, there is 63+ of total in the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script decouples species and expressions into a big, single column CSV files\n",
    "# %run -i paco-ds-merge-data.py\n",
    "\n",
    "# ...and this script reads the decoupled CSV files and plots the data for it\n",
    "%run -i paco-ds-species-2021.py"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cccef0b623dea535a8b0ba63ca3bed1c9df0f45edf1dfc4827d6800098bd789"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
